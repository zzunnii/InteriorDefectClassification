#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ì¸í…Œë¦¬ì–´ ê²°í•¨ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import sys
import argparse
import time
import json
import torch
import numpy as np
import pandas as pd
from collections import defaultdict

import config
from utils import (
    seed_everything, collect_images, calculate_class_weights,
    create_soft_label_matrix, ensure_dir, save_json,
    get_model_by_name, create_data_loaders,
    train_model, test_model,
    plot_confusion_matrix, plot_learning_curves, plot_class_accuracy
)


def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="ì¸í…Œë¦¬ì–´ ê²°í•¨ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")

    parser.add_argument("--model", type=str, default="all",
                        choices=list(config.MODELS.keys()) + ["all"],
                        help="í•™ìŠµí•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: all)")

    parser.add_argument("--data-dir", type=str, default=config.DATA_DIR,
                        help=f"ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: {config.DATA_DIR})")

    parser.add_argument("--use-soft-labels", action="store_true", default=True,
                        help="ì†Œí”„íŠ¸ ë ˆì´ë¸” ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)")

    parser.add_argument("--seed", type=int, default=42,
                        help="ë‚œìˆ˜ ì‹œë“œ (ê¸°ë³¸ê°’: 42)")

    parser.add_argument("--no-cuda", action="store_true",
                        help="CUDA ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’: False)")

    return parser.parse_args()


def prepare_data(data_dir, class_to_idx):
    """ë°ì´í„° ì¤€ë¹„"""
    # ê²½ë¡œ ì„¤ì •
    train_dir = os.path.join(data_dir, "train")
    val_dir = os.path.join(data_dir, "val")
    test_dir = os.path.join(data_dir, "test")

    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
    train_paths, train_labels = collect_images(train_dir, class_to_idx)
    val_paths, val_labels = collect_images(val_dir, class_to_idx)
    test_paths, test_labels = collect_images(test_dir, class_to_idx)

    # ë°ì´í„° í˜•ì‹ ë§ì¶”ê¸°
    train_data = [{"image": path, "label": label} for path, label in zip(train_paths, train_labels)]
    val_data = [{"image": path, "label": label} for path, label in zip(val_paths, val_labels)]
    test_data = [{"image": path, "label": label} for path, label in zip(test_paths, test_labels)]

    print(f"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}")

    return train_data, val_data, test_data, train_labels


def train_single_model(model_name, train_data, val_data, test_data, class_names,
                       class_to_idx, train_labels, device, use_soft_labels=False):
    """ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
    # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    model_config = config.MODELS[model_name]
    model_dir = model_config["result_dir"]
    ensure_dir(model_dir)

    print(f"\n\n{'=' * 20}  {model_config['display_name']} í•™ìŠµ ì‹œì‘  {'=' * 20}")

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    num_classes = len(class_names)
    class_weights = calculate_class_weights(train_labels, num_classes)
    class_weights_tensor = torch.tensor(class_weights).float().to(device)
    print("í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ âœ", np.round(class_weights, 3))

    # ì†Œí”„íŠ¸ ë ˆì´ë¸” ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± (ì‚¬ìš© ì„¤ì • ì‹œ)
    soft_label_matrix = None
    if use_soft_labels:
        soft_label_matrix = create_soft_label_matrix(
            class_names, config.SOFT_LABEL_MAPPING, default_weight=config.SOFT_LABEL_WEIGHT
        )
        print(f"ì†Œí”„íŠ¸ ë ˆì´ë¸” ì ìš© (ê¸°ë³¸ ê°€ì¤‘ì¹˜: {config.SOFT_LABEL_WEIGHT})")

    # ë°ì´í„° ë¡œë” ìƒì„±
    train_loader, val_loader, test_loader = create_data_loaders(
        train_data, val_data, test_data,
        batch_size=config.TRAIN_CONFIG["batch_size"],
        soft_label_matrix=soft_label_matrix,
        img_size=config.TRAIN_CONFIG["image_size"],
        num_workers=config.TRAIN_CONFIG["num_workers"]
    )

    # ëª¨ë¸ ìƒì„±
    model = get_model_by_name(model_name, num_classes).to(device)

    # ëª¨ë¸ í•™ìŠµ
    model, history, best_val_f1, training_time = train_model(
        model, train_loader, val_loader, device,
        config=config.TRAIN_CONFIG,
        model_dir=model_dir,
        use_soft_labels=use_soft_labels,
        class_weights_tensor=class_weights_tensor
    )

    # í…ŒìŠ¤íŠ¸ í‰ê°€
    test_results = test_model(
        model, test_loader, device, class_names, class_weights_tensor
    )

    # ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
    plot_confusion_matrix(
        test_results["confusion_matrix"], class_names,
        title=f"Confusion Matrix - {model_config['display_name']}",
        save_path=os.path.join(model_dir, "confusion_matrix.png")
    )

    plot_learning_curves(
        history, save_path=os.path.join(model_dir, "learning_curves.png")
    )

    plot_class_accuracy(
        test_results["class_accuracy"],
        title=f"Class-wise Accuracy - {model_config['display_name']}",
        save_path=os.path.join(model_dir, "class_accuracy.png")
    )

    # ê²°ê³¼ ì •ë³´ ì €ì¥
    results_info = {
        "model_name": model_name,
        "display_name": model_config["display_name"],
        "use_soft_labels": use_soft_labels,
        "training_config": config.TRAIN_CONFIG,
        "class_weights": class_weights,
        "best_val_f1": float(best_val_f1),
        "training_time": float(training_time),
        "training_time_min": float(training_time) / 60,
        "test_accuracy": float(test_results["test_acc"]),
        "test_f1": float(test_results["test_f1"]),
        "class_accuracy": test_results["class_accuracy"],
        "history": {
            "train_loss": [float(x) for x in history["train_loss"]],
            "train_acc": [float(x) for x in history["train_acc"]],
            "val_loss": [float(x) for x in history["val_loss"]],
            "val_acc": [float(x) for x in history["val_acc"]],
            "val_f1": [float(x) for x in history["val_f1"]]
        },
        "epochs_trained": len(history["train_loss"])
    }

    # ê²°ê³¼ JSON ì €ì¥
    save_json(results_info, os.path.join(model_dir, "results.json"))

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata = {
        "model_name": model_name,
        "display_name": model_config["display_name"],
        "num_classes": num_classes,
        "class_names": class_names,
        "class_to_idx": class_to_idx,
        "use_soft_labels": use_soft_labels,
        "soft_label_mapping": config.SOFT_LABEL_MAPPING if use_soft_labels else None,
        "soft_label_weight": config.SOFT_LABEL_WEIGHT if use_soft_labels else None
    }

    save_json(metadata, os.path.join(model_dir, "metadata.json"))

    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ëª¨ë¸ê³¼ ê´€ë ¨ ê°ì²´ ì‚­ì œ
    del model
    torch.cuda.empty_cache()

    return results_info


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    args = parse_args()

    # ì‹œë“œ ê³ ì •
    seed_everything(args.seed)

    # CUDA ì„¤ì •
    use_cuda = config.USE_CUDA and torch.cuda.is_available() and not args.no_cuda
    device = torch.device("cuda" if use_cuda else "cpu")
    if use_cuda and config.CUDA_VISIBLE_DEVICES:
        os.environ["CUDA_VISIBLE_DEVICES"] = config.CUDA_VISIBLE_DEVICES

    print(f"Device: {device}")

    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    ensure_dir(config.RESULTS_DIR)

    # í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
    train_dir = os.path.join(args.data_dir, "train")
    class_names = sorted(os.listdir(train_dir))
    class_to_idx = {cls: i for i, cls in enumerate(class_names)}
    num_classes = len(class_names)

    print(f"í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
    print(f"í´ë˜ìŠ¤ ì´ë¦„: {class_names}")

    # ë°ì´í„° ì¤€ë¹„
    train_data, val_data, test_data, train_labels = prepare_data(args.data_dir, class_to_idx)

    # í•™ìŠµí•  ëª¨ë¸ ê²°ì •
    models_to_train = list(config.MODELS.keys()) if args.model == "all" else [args.model]

    # ê²°ê³¼ ì €ì¥
    all_results = {}

    # ê° ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    for model_name in models_to_train:
        try:
            results_info = train_single_model(
                model_name, train_data, val_data, test_data,
                class_names, class_to_idx, train_labels,
                device, use_soft_labels=args.use_soft_labels
            )
            all_results[model_name] = results_info
        except Exception as e:
            print(f"Error training {model_name}: {e}")
            import traceback
            traceback.print_exc()

    # ì „ì²´ ê²°ê³¼ ì €ì¥
    result_summary = {
        "models": all_results,
        "args": vars(args),
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }

    # ì†Œí”„íŠ¸ ë ˆì´ë¸” ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ íŒŒì¼ëª… ì‚¬ìš©
    summary_filename = "results_summary_soft.json" if args.use_soft_labels else "results_summary.json"
    save_json(result_summary, os.path.join(config.RESULTS_DIR, summary_filename))

    # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ í‘œ ì¶œë ¥
    print("\n\n==== ëª¨ë¸ë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ ====")
    results_df = pd.DataFrame({
        "ëª¨ë¸": [config.MODELS[m]["display_name"] for m in all_results.keys()],
        "ì •í™•ë„": [all_results[m]["test_accuracy"] for m in all_results.keys()],
        "F1 ìŠ¤ì½”ì–´": [all_results[m]["test_f1"] for m in all_results.keys()],
        "í•™ìŠµ ì‹œê°„(ë¶„)": [all_results[m]["training_time_min"] for m in all_results.keys()]
    })

    print(results_df.sort_values("F1 ìŠ¤ì½”ì–´", ascending=False).to_string(index=False))

    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì¶œë ¥
    if all_results:
        best_model = max(all_results.items(), key=lambda x: x[1]["test_f1"])
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {config.MODELS[best_model[0]]['display_name']} (F1: {best_model[1]['test_f1']:.4f})")

    print("\nëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")


if __name__ == "__main__":
    main()